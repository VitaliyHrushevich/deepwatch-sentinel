import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç–∏ –ø–æ–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.core.llm_client import ask_ollama
from src.simple_check import get_ai_analytic_report, get_all_significant_tests


def start_sentinel():
    print("üõ∞Ô∏è DeepWatch Sentinel System: Booting...")

    # 1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (Context Collection)
    print("üîç Collecting metrics and historical trends...")
    latest_report = get_ai_analytic_report()
    history = get_all_significant_tests()

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ò–ò
    full_context = (
        f"–î–ê–ù–ù–´–ï –ü–û–°–õ–ï–î–ù–ï–ì–û –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê:\n{latest_report}\n\n"
        f"–ò–°–¢–û–†–ò–Ø –£–°–ü–ï–®–ù–´–• –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í:\n{history}"
    )

    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
    question = (
        "–°—Ä–∞–≤–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π –ø—Ä–æ—à–ª—ã—Ö —Ç–µ—Å—Ç–æ–≤. "
        "–ù–∞—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ –º—ã —É–ª—É—á—à–∞–µ–º —Å–∏—Å—Ç–µ–º—É? "
        "–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –≤–µ—Ä–¥–∏–∫—Ç: –≥–æ—Ç–æ–≤—ã –ª–∏ –º—ã –∫ —Ä–µ–ª–∏–∑—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è?"
    )

    print("ü§ñ AI Agent is analyzing data patterns...")

    try:
        # 3. –í—ã–∑–æ–≤ –ò–ò (–£–±–µ–¥–∏—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å llama3 —Å–∫–∞—á–∞–Ω–∞)
        response = ask_ollama(
            user_query=question,
            context_data=full_context,
            model="llama3"
        )

        print("\n" + "‚Äî" * 50)
        print("üü¢ SENTINEL FINAL VERDICT:")
        print(response)
        print("‚Äî" * 50)

    except Exception as e:
        print(f"‚ùå System Error: {e}")


if __name__ == "__main__":
    start_sentinel()
